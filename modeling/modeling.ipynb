{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Setting"
      ],
      "metadata": {
        "id": "aTuUWy2UbeWZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdPcLE6VXLbW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from transformers import AutoModel, AutoTokenizer, AdamW, get_cosine_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, SubsetRandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "# for graphing\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63QFDxeoXUHL",
        "outputId": "ca930147-219b-4a71-ae27-b882c9982158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### def seed_everything(seed)"
      ],
      "metadata": {
        "id": "cDkpLHUrbgiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#시드 설정\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    print(\"1. Seed 설정이 완료되었습니다.\")"
      ],
      "metadata": {
        "id": "aIP8SpO8Xha8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CFG   "
      ],
      "metadata": {
        "id": "Y5f4wbMWbkwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습 및 설정에 사용되는 여러 하이퍼파라미터 및 구성 옵션들을 저장한 딕셔너리"
      ],
      "metadata": {
        "id": "FGXcrME9cusD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델의 여러 초매개변수 및 구성 설정\n",
        "\n",
        "CFG = {\n",
        "    'EPOCHS': 20,\n",
        "    'LEARNING_RATE':5e-5,\n",
        "    'BATCH_SIZE':64,\n",
        "    'SEED':40,\n",
        "    'MAX_LENGTH': 65,\n",
        "    'PATIENCE': 5,\n",
        "    'K': 3,\n",
        "    'WARMUP_RATIO': 0.1\n",
        "}"
      ],
      "metadata": {
        "id": "LxpNZLy0XkKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "id": "gI5akvWIXnc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### device"
      ],
      "metadata": {
        "id": "PYvzp4TYdYVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU 설정"
      ],
      "metadata": {
        "id": "q2SsjJbEdZuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "DMHAZszpXlp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sent_type"
      ],
      "metadata": {
        "id": "XkOTYR0mbr0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "감정 클래스와 해당 숫자 인덱스를 매핑한 딕셔너리"
      ],
      "metadata": {
        "id": "58hAunwycxFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_type = {0:'angry', 1:'fear', 2:'happy', 3:'sad', 4:'neutral'}  # 라벨링"
      ],
      "metadata": {
        "id": "3BaMvBPEZeTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### class sentenceDataset(Dataset)  "
      ],
      "metadata": {
        "id": "TbP2hrGZbvBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트 데이터셋을 PyTorch의 Dataset으로 구현한 클래스.   \n",
        "데이터를 토큰화하고 레이블을 포함하여 모델 학습에 사용될 수 있는 형식으로 변환."
      ],
      "metadata": {
        "id": "bklDMLXLczQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class sentenceDataset(Dataset):\n",
        "    def __init__(self, dataframe, sent_col, tokenizer, labels=None):\n",
        "        texts = dataframe[sent_col].values.tolist()\n",
        "\n",
        "        # Tokenize each text using the provided tokenizer\n",
        "        self.texts = [tokenizer(text, padding='max_length', max_length = CFG['MAX_LENGTH'], truncation=True, return_tensors='pt') for text in texts]\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "\n",
        "        if self.labels is not None:\n",
        "            # If labels are provided, get the corresponding label\n",
        "            type_tmp = self.labels['type'][idx]\n",
        "            return text, torch.Tensor(type_tmp).to(device)\n",
        "        else:\n",
        "            # If no labels, return a placeholder tensor\n",
        "            return text, torch.Tensor([-1,-1,-1,-1]).to(device)"
      ],
      "metadata": {
        "id": "viIKu0q0MC1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### class sentenceClassifier(nn.Module)"
      ],
      "metadata": {
        "id": "W7p9Wzjxbzi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트 분류를 위한 PyTorch 모델 클래스.    \n",
        " 기본 모델을 기반으로 하여 선형 레이어와 소프트맥스 레이어를 사용하여 텍스트를 클래스로 분류."
      ],
      "metadata": {
        "id": "d8fuIewRc1RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class sentenceClassifier(nn.Module):               # 텍스트 분류 작업을 수행\n",
        "    def __init__(self, base_model):\n",
        "        super().__init__()\n",
        "        self.klue = base_model # from transformers package\n",
        "\n",
        "        self.fc1 = nn.Linear(768, 5).to(device) #input : 768차원 output : 5차원 선형 레이어 # 0:'angry', 1:'fear', 2:'happy', 3:'sad', 4:'neutral'\n",
        "        self.softmax = nn.Softmax(dim = 1).to(device)\n",
        "\n",
        "    #forward 연산\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        klue_out = self.klue(input_ids= input_ids, attention_mask = attention_mask)[0][:,0]  #주어진 입력 (input_ids 및 attention_mask)을 기반 모델에 전달하고, 그 결과에서 첫 번째 토큰의 출력만 선택\n",
        "\n",
        "        x = self.fc1(klue_out).to(device)     #선택된 출력을 선형 레이어에 전달하여 클래스별 로직 생성\n",
        "        x = self.softmax(x).to(device)        # softmax에 통과시켜 확률 분포로 변환\n",
        "\n",
        "        return x                              # 확률분포로 반환"
      ],
      "metadata": {
        "id": "uM9sZh-YXwK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### def calc_label_accuracy(X, Y)  "
      ],
      "metadata": {
        "id": "hO8xvj3Db3wZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 예측과 실제 레이블을 비교하여 각 클래스별 정확도를 계산하는 함수."
      ],
      "metadata": {
        "id": "v9c68S4jc3Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_label_accuracy(X,Y):                           #레이블 정확도를 계산하는 함수\n",
        "    _, max_indices = torch.max(X, 1)                   #모델의 출력 X에서 가장 큰 값을 갖는 인덱스를 찾아 max_indices에 저장. 이것은 모델이 각 샘플에 대해 예측한 클래스\n",
        "    label = [0 for _ in range(5)]                      #실제 dataset의 각 감정 레이블당 갯수를 저장하기 위한 리스트. 5개의 클래스\n",
        "    acc = [0 for _ in range(5)]                        #inference 후, 각 감정 레이블당 갯수를 저장하기 위한 리스트. 5개의 클래스\n",
        "\n",
        "    for i, j in zip(max_indices, Y):                  #모델의 예측값과 실제 레이블을 반복하여 비교\n",
        "        l_val = ((j == 1).nonzero().flatten().tolist())[0]     #실제 레이블 j에서 값이 1인 인덱스를 찾아서 l_val에 저장, 원-핫 인코딩된 레이블에서 실제 클래스를 찾는 거승로 보임\n",
        "        label[l_val] += 1                                #실제 데이터셋에서 해당 클래스의 수를 증가\n",
        "        if i == l_val:                                     #모델이 예측한 클래스가 실제 클래스와 일치하면 해당 클래스에 대한 정확도를 증가\n",
        "            acc[i] += 1\n",
        "\n",
        "    ans = [] #각 레이블당 accuracy                         #각 클래스에 대한 정확도를 저장할 빈 리스트를 초기화\n",
        "    for i in range(5):                                     #각 클래스에 대해 정확도를 계산\n",
        "      if label[i] != 0:                                    #해당 클래스에 대한 데이터가 존재하는 경우, 정확도를 계산하여 리스트에 추가\n",
        "        ans.append(np.round(acc[i]/label[i], 2))\n",
        "      else:                                                 #해당 클래스에 대한 데이터가 없는 경우, 정확도를 0으로 설정\n",
        "        ans.append(0)\n",
        "\n",
        "    return ans                                             #계산된 정확도를 반환"
      ],
      "metadata": {
        "id": "0Bt8Aq6hXy5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### def loss_graph(train_loss, val_loss, file_path)"
      ],
      "metadata": {
        "id": "4BRgKg_Tb94r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 손실(train loss)과 검증 손실(validation loss)의 추이를 시각화하여 저장하는 함수"
      ],
      "metadata": {
        "id": "YNSuXI1fdBaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot for train loss and validation loss\n",
        "def loss_graph(train_loss, val_loss, file_path):\n",
        "    plt.figure(figsize=(13, 6))\n",
        "\n",
        "    # 전체 Train Loss 그래프\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_loss, label='Train Loss')\n",
        "    plt.title('Overall Train Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # 전체 Validation Loss 그래프\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.title('Overall Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_path)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4znBLWMcGqGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### def accuracy_graph(train_accuracies, val_accuracies, sent_types, file_path)"
      ],
      "metadata": {
        "id": "twGTV4955Nvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_graph(train_accuracies, val_accuracies, sent_types, file_path):\n",
        "    plt.figure(figsize=(13, 6))\n",
        "\n",
        "    # 전체 Train Accuracy 그래프\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_accuracies, label='Train Accuracy')\n",
        "    plt.title('Overall Train Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # 전체 Validation Accuracy 그래프\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "    plt.title('Overall Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_path)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5U7pi_6W6gGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###def train(model, train_dataloader, val_dataloader, learning_rate, epochs)"
      ],
      "metadata": {
        "id": "DBVWir5jcjjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader, val_dataloader, learning_rate, epochs):\n",
        "    avg_val_losses, avg_train_losses = [], []                                    #epoch 당 평균 loss를 저장할 리스트\n",
        "    avg_train_accuracies, avg_val_accuracies = [], []\n",
        "\n",
        "    criterion = {                                                                #분류 작업에서 사용할 손실 함수를 정의. CrossEntropyLoss를 사용하고, GPU로 이동\n",
        "        'type' : nn.CrossEntropyLoss().to(device)\n",
        "        }\n",
        "\n",
        "    no_decay = ['bias', 'LayerNorm.weight']                                      # 가중치 감쇠를 적용하지 않을 레이어 설정 #옵티마이저와 관련된 설정\n",
        "    optimizer_grouped_parameters = [                                             # 옵티마이저의 그룹 파라미터 설정\n",
        "      {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "      {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "      ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr = learning_rate)          #옵티마이저는 AdamW를 사용, 학습률은 주어진 learning_rate로 설정\n",
        "    model = model.to(device)                                                     #모델을 GPU로 이동\n",
        "\n",
        "    t_total = len(train_dataloader) * CFG['EPOCHS']                              # 총 훈련 스텝 계산\n",
        "    warmup_step = int(t_total * CFG['WARMUP_RATIO'])                             # 워밍업 스텝 계산\n",
        "\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)   # 코사인 스케줄러 설정\n",
        "\n",
        "    # 에폭 루프\n",
        "    for epoch in range(epochs):\n",
        "        val_losses, train_losses = [], []                                        # 에폭마다 손실과 정확도를 저장할 리스트 초기화\n",
        "\n",
        "        train_accuracy = [0 for _ in range(5)]\n",
        "        val_accuracy = [0 for _ in range(5)]\n",
        "\n",
        "        model.train()                                                            # 훈련 모드로 모델 전환\n",
        "\n",
        "        # 훈련 데이터셋 루프\n",
        "        print(\"훈련 루프가 시작되었습니다.\")\n",
        "        for batch_id, (train_input, type_label) in tqdm(enumerate(train_dataloader)):\n",
        "            attention_mask = train_input['attention_mask'].to(device)            # 입력 데이터를 GPU로 이동\n",
        "            input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
        "            type_label = type_label.to(device)\n",
        "            optimizer.zero_grad()                                                # 옵티마이저 초기화\n",
        "\n",
        "            type_output = model(input_ids, attention_mask)                       # 모델에 입력 전달하여 예측 얻기\n",
        "\n",
        "            loss = criterion['type'](type_output, type_label)                    # 손실 계산\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()                                                     # 옵티마이저 업데이트\n",
        "            scheduler.step()                                                     # 스케줄러 업데이트\n",
        "            train_losses.append(loss.item())                                     # 훈련 손실 기록\n",
        "\n",
        "\n",
        "            for i in range(5):                                                   # 정확도 계산 및 누적\n",
        "              acc = calc_label_accuracy(type_output, type_label)\n",
        "              train_accuracy[i] += acc[i]\n",
        "            # print(f\"현재 배치: {batch_id + 1}, 현재 손실: {loss.item()}\")\n",
        "\n",
        "\n",
        "        for i in range(5):                                                     # 각 클래스별 훈련 정확도 출력\n",
        "          print(f\"⦁ Train acc for label {sent_type[i]}: {train_accuracy[i] / (batch_id+1)}\")\n",
        "\n",
        "        avg_train_accuracies.append(sum(train_accuracy) / len(train_accuracy))\n",
        "\n",
        "\n",
        "\n",
        "        # 검증 데이터셋 루프\n",
        "        print(\"검증 루프가 시작되었습니다.\")\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "\n",
        "            # same process as the above\n",
        "            for  batch_id, (val_input, vtype_label) in tqdm(enumerate(val_dataloader)):\n",
        "                attention_mask = val_input['attention_mask'].to(device)          # 입력 데이터를 GPU로 이동\n",
        "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
        "                vtype_label = vtype_label.to(device)\n",
        "\n",
        "                vtype_output = model(input_ids, attention_mask)                  # 모델에 입력 전달하여 예측 얻기\n",
        "\n",
        "                loss = criterion['type'](vtype_output, vtype_label)      # 검증 손실 기록\n",
        "                val_losses.append(loss.item())\n",
        "\n",
        "                for i in range(5):\n",
        "                  acc = calc_label_accuracy(vtype_output, vtype_label)           # 정확도 계산 및 누적\n",
        "                  val_accuracy[i] += acc[i]\n",
        "\n",
        "            for i in range(5):                                                   # 각 클래스별 검증 정확도 출력\n",
        "              print(f\"⦁ Val acc for label {sent_type[i]}: {val_accuracy[i] / (batch_id+1)}\")\n",
        "\n",
        "            avg_val_accuracies.append(sum(val_accuracy) / len(val_accuracy))\n",
        "\n",
        "            train_loss = np.average(train_losses)                                 # 에폭마다 훈련 및 검증 손실 출력\n",
        "            val_loss = np.average(val_losses)\n",
        "\n",
        "\n",
        "            avg_train_losses.append(train_loss)\n",
        "            avg_val_losses.append(val_loss)\n",
        "\n",
        "            print(f\" ▶ epoch {epoch+1} ◀ train_loss: {train_loss:.4f} val_loss: {val_loss:.4f}\")\n",
        "            print()\n",
        "\n",
        "    loss_graph(avg_train_losses, avg_val_losses,'/content/drive/MyDrive/Emotion/model/loss_plot.png')\n",
        "    accuracy_graph(avg_train_accuracies, avg_val_accuracies, sent_type,  '/content/drive/MyDrive/Emotion/model/accuracy_plot.png')\n",
        "    #torch.save(model.state_dict(), '/content/drive/MyDrive/Emotion/model/klueroberta_trained_model.pth')\n",
        "\n",
        "    return model       # 최종 훈련된 모델 반환"
      ],
      "metadata": {
        "id": "WhsW0rPHX2Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### def encode_label(data, label_col)"
      ],
      "metadata": {
        "id": "9BX-iLiPgKha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "감정 레이블 원-핫 인코딩"
      ],
      "metadata": {
        "id": "bPMD2Y7QglMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_label(data, label_col):\n",
        "    data_tmp =pd.get_dummies(data, columns=[label_col])      #입력 데이터프레임(data)의 label_col 열에 대해 원-핫 인코딩을 수행. 결과로 나온 더미 변수들을 새로운 데이터프레임(data_tmp)으로 저장\n",
        "    data_labels = {                                          #데이터프레임에서 1부터 4까지의 열을 슬라이싱하여 해당하는 레이블에 대한 원-핫 인코딩된 값들을 가져와 리스트로 변환.\n",
        "        'type': data_tmp.iloc[:, 1:].values.tolist()        #we have 5 labels  #이 리스트를 딕셔너리에 저장하고, 'type'이라는 키로 반환합니다.\n",
        "        }\n",
        "    return data_labels                                       #원-핫 인코딩된 레이블을 담고 있는 딕셔너리를 반환. 이 딕셔너리는 모델의 훈련 시에 사용됨."
      ],
      "metadata": {
        "id": "ye6OzT-UX4Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### def run_classifier():"
      ],
      "metadata": {
        "id": "vZkwYpwGgnD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 감정 분류 모델을 실행하는 함수"
      ],
      "metadata": {
        "id": "LDDd0iICgro1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_classifier():\n",
        "    # 데이터 및 모델 설정\n",
        "    data_path = \"/content/drive/MyDrive/Emotion/data/data.csv\"\n",
        "    sent_col = 'Sentence'\n",
        "    label_col = 'Emotion'\n",
        "    model_name = 'klue/roberta-small'\n",
        "    seed_everything(CFG['SEED']) # Seed 고정\n",
        "\n",
        "\n",
        "     # 데이터 로드 및 훈련/테스트 분리\n",
        "    data = pd.read_csv(data_path, encoding='CP949')\n",
        "    train1, test = train_test_split(data, test_size=0.2, random_state=CFG['SEED'])\n",
        "    train1 = train1.reset_index(drop=True)\n",
        "    print(\"2. 데이터가 성공적으로 로드되었습니다.\")\n",
        "\n",
        "\n",
        "    # 모델 및 토크나이저 설정\n",
        "    base_model = AutoModel.from_pretrained(model_name)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = sentenceClassifier(base_model)\n",
        "    #model.load_state_dict(torch.load('/home/ubuntu/model/pre-trained/klueroberta_crossVal_epoch40.pt', map_location = device))\n",
        "\n",
        "\n",
        "     # K-fold 교차 검증을 위한 설정\n",
        "    k = CFG['K']\n",
        "    skf = StratifiedKFold(n_splits = k, shuffle = True, random_state=CFG['SEED'])\n",
        "\n",
        "\n",
        "    # 각 폴드에 대해 훈련 및 검증 수행\n",
        "    print(\"3. 각 폴드에 대해 훈련 및 검증 수행\")\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(train1[sent_col], train1[label_col])):\n",
        "        print('Fold {}'.format(fold + 1))\n",
        "        if fold == 0:\n",
        "\n",
        "            # 훈련 및 검증 레이블 인코딩 및 데이터 샘플 구성\n",
        "            train_labels = encode_label(train1.loc[train_idx], label_col)\n",
        "            val_labels = encode_label(train1.loc[val_idx], label_col)\n",
        "            print(f\"train & val encode_label success\")\n",
        "\n",
        "            train_sample = sentenceDataset(train1.loc[train_idx], sent_col, tokenizer, train_labels)\n",
        "            val_sample = sentenceDataset(train1.loc[val_idx], sent_col, tokenizer, val_labels)\n",
        "\n",
        "\n",
        "            # 데이터로더 설정\n",
        "            train_dataloader = DataLoader(train_sample, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
        "            val_dataloader = DataLoader(val_sample, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
        "\n",
        "            print(\"4.  훈련 데이터셋 크기:\", len(train_sample), \"검증 데이터셋 크기:\", len(val_sample) )\n",
        "            print()\n",
        "\n",
        "            # 모델 훈련\n",
        "            model = train(model, train_dataloader, val_dataloader, CFG['LEARNING_RATE'], CFG['EPOCHS'])\n",
        "\n",
        "    # 테스트 및 평가\n",
        "    test_labels = encode_label(test, label_col)\n",
        "    test_accuracy = [0 for _ in range(5)]\n",
        "\n",
        "    test_set = sentenceDataset(test, sent_col, tokenizer, test_labels)\n",
        "    test_dataloader = DataLoader(test_set, batch_size=CFG['BATCH_SIZE'], shuffle = True, num_workers = 0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for batch_id, (test_input, t_label) in tqdm(enumerate(test_dataloader)):\n",
        "            attention_mask = test_input['attention_mask'].to(device)\n",
        "            input_ids = test_input['input_ids'].squeeze(1).to(device)\n",
        "            t_label = t_label.to(device)\n",
        "\n",
        "            # 테스트 데이터에 대한 예측 수행\n",
        "            test_output = model(input_ids, attention_mask) # from the forward function\n",
        "\n",
        "            # 클래스별 정확도 계산\n",
        "            for i in range(5):\n",
        "                acc = calc_label_accuracy(test_output, t_label)\n",
        "                test_accuracy[i] += acc[i]\n",
        "\n",
        "        print()\n",
        "        print(f\"￭ 테스트 정확도: {test_accuracy[i] / (batch_id + 1)}\")\n",
        "\n",
        "        # 클래스별 테스트 정확도 출력\n",
        "        for i in range(5):\n",
        "            print(f\"⦁ Test acc for label {sent_type[i]}: {test_accuracy[i] / (batch_id+1)}\")"
      ],
      "metadata": {
        "id": "mvtgMGqaX7NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    run_classifier()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE1cZWy6Cj1b",
        "outputId": "5372aa7b-fccb-4497-8276-bd93dc83423b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Seed 설정이 완료되었습니다.\n",
            "2. 데이터가 성공적으로 로드되었습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. 각 폴드에 대해 훈련 및 검증 수행\n",
            "Fold 1\n",
            "train & val encode_label success\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.  훈련 데이터셋 크기: 20583 검증 데이터셋 크기: 10292\n",
            "\n",
            "훈련 루프가 시작되었습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "322it [01:54,  2.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⦁ Train acc for label angry: 0.6899068322981367\n",
            "⦁ Train acc for label fear: 0.6982298136645964\n",
            "⦁ Train acc for label happy: 0.47875776397515546\n",
            "⦁ Train acc for label sad: 0.0038198757763975156\n",
            "⦁ Train acc for label neutral: 0.17295031055900614\n",
            "검증 루프가 시작되었습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "161it [00:21,  7.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⦁ Val acc for label angry: 0.8244720496894409\n",
            "⦁ Val acc for label fear: 0.6550310559006213\n",
            "⦁ Val acc for label happy: 0.8463354037267077\n",
            "⦁ Val acc for label sad: 0.0004347826086956522\n",
            "⦁ Val acc for label neutral: 0.4611180124223601\n",
            " ▶ epoch 1 ◀ train_loss: 1.3987 val_loss: 1.2713\n",
            "\n",
            "훈련 루프가 시작되었습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "322it [01:52,  2.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⦁ Train acc for label angry: 0.7629503105590066\n",
            "⦁ Train acc for label fear: 0.7028881987577641\n",
            "⦁ Train acc for label happy: 0.7624223602484469\n",
            "⦁ Train acc for label sad: 0.15295031055900615\n",
            "⦁ Train acc for label neutral: 0.5181366459627327\n",
            "검증 루프가 시작되었습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "161it [00:21,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⦁ Val acc for label angry: 0.6100000000000003\n",
            "⦁ Val acc for label fear: 0.7624844720496896\n",
            "⦁ Val acc for label happy: 0.6921118012422359\n",
            "⦁ Val acc for label sad: 0.28770186335403725\n",
            "⦁ Val acc for label neutral: 0.6421739130434783\n",
            " ▶ epoch 2 ◀ train_loss: 1.2660 val_loss: 1.2697\n",
            "\n",
            "훈련 루프가 시작되었습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "175it [01:01,  2.90it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wV88svtyHTie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}